\chapter{Analisi Statica}

\begin{epigraphs}
\qitem{"As soon as we started  
programming, we found to  
our surprise that it wasn’t as  
easy to get programs right as  
we had thought.  Debugging  
had to be discovered. I can 
remember the exact instant  
when I realized that a large  
part of my life from then on  
was going to be spent in finding 
mistakes in my own programs."}{---\textsc{ Maurice Wilkes, Inventore di EDSAC, 1949}}
\end{epigraphs}

Tutti i progetti software condividono una caratteristica fondamentale: possiedono un codice sorgente che ne definisce il funzionamento. Il codice sorgente è costituito da una serie di istruzioni scritte in un linguaggio di programmazione che vengono interpretate da un compilatore e successivamente eseguite. Il codice sorgente di un software risiede tipicamente su uno o più files di testo.\\
Il codice sorgente non è esente da errori bensì ha l'intrinseca proprietà di possedere difetti. Sin dagli albori della programmazione software gli sviluppatori hanno avuto a che fare con tali difetti, individuando un rapporto di proporzionalità diretta tra il numero di questi ultimi ed il numero di righe di codice scritte per un determinato software. L'aumentare della complessità dei programmi e la necessità di affidabilità hanno reso il controllo dei difetti fondamentale nell'industria del software, tanto che è opportuno che prima di un rilascio determinati standard di qualità siano rispettati. \\
Al fine di ridurre il quantitativo di difetti nel software e di aderire agli standard i programmatori hanno pensato di sviluppare altro software in grado di analizzare il codice sorgente di un programma durante la fase di sviluppo.\\
Tale analisi è detta \emph{analisi statica} ed è una tecnica che consiste nell'ispezionare automaticamente il codice sorgente di un software senza però eseguirlo. Il grosso vantaggio di tale tecnica consiste nella sua applicazione alla radice del processo di sviluppo, in contrasto alle esistenti tecniche di testing che vedevano posticipata la correzione dei difetti alla fase di pre-rilascio. Anticipare l'identificazione del difetto software comporta minori costi di correzione; è proprio questo il motivo del successo dell'analisi statica.

\section{Il problema}
Alan Touring\cite{turing} nel 1937 affermò che esistono due tipologie di problemi: problemi decidibili, per i quali esiste un algoritmo (quindi una procedura eseguibile con un numero finito di passi) in grado di risolverli e problemi non decidibili, per i quali non esiste alcun algoritmo in grado di dare una risposta in tempo finito su tutte le istanze del problema. Henry Gordon Rice estese tale teorema\cite{rice}, asserendo che ogni domanda non banale riguardante il comportamento di un programma è indecidibile. Di conseguenza non esiste alcun metodo meccanico per determinare se un dato programma può o non può generare errori di esecuzione.\\
L'analisi statica è quindi un problema non decidibile. Alcuni fattori non possono infatti essere valutati se non dinamicamente e dipendono strettamente dalle condizioni di input. Essendo non decidibile, l'analisi statica genererà sempre falsi positivi e negativi e non garantisce che i risultati siano corretti. L'accuratezza consiste nel determinare un buon livello di approssimazione al fine di ridurre i falsi.

\section{Storia}
Il primo approccio all'analisi statica è storicamente da attribuire al tool di Unix \emph{grep}\footnote{General Regular Expression Print}, che effettua una ricerca in uno o più file di testo di linee corrispondenti ad uno o più modelli specificati con espressioni regolari o stringhe letterali.
Grep non conosce nessun dettaglio dei files che sta esaminando, li interpreta semplicemente come files di testo, di conseguenza sebbene possa produrre risultati apprezzabili con determinati pattern di ricerca non si può considerare come un vero e proprio tool di analisi statica. \\
Per aumentare la fedeltà nei risultati è importante che vengano prese in considerazione le regole lessicali specifiche del linguaggio, al fine di poter distinguere tra i vari costrutti.\\  
La vera nascita delle tecniche di analisi statica viene solitamente attribuita al tool Lint, sviluppato da Stephen C. Johnson e rilasciato alla fine degli anni '70. Lint fu realizzato allo scopo di segnalare come sospetti alcuni costrutti nel sorgente in linguaggio C, come la mancanza di punti e virgola, parentesi, cast impliciti, ecc. 
Lint era integrato con il processo di compilazione, soluzione che sembrava essere la migliore per riportare segnalazioni relative al codice e che ne contribuì alla diffusione.\\
Purtroppo le limitate capacità di analisi, quali ad esempio l'obbligo di eseguire la scansione un file per volta, fecero si che Lint riportasse un elevata percentuale di rumore tra i risultati, ovvero valori corretti dal punto di vista dell'analisi ma irrilevanti per lo sviluppatore al fine di correggere difetti. Ciò si tradusse nella necessità di eseguire dei controlli manuali sui risultati di Lint, esattamente la situazione che Lint si era proposto di eliminare.
Per tale motivo Lint non fu mai adottato globalmente come tool per l'individuazione di difetti.\\
Nei primi anni 2000 una seconda generazione di tools emerse, che si è evoluta fino ad oggi. Gli sviluppatori intuirono che era necessario comprendere attraverso il software di analisi maggiori dettagli relativi al funzionamento del programma. Produssero tools in grado di  analizzare più files contemporaneamente e di identificare i percorsi di flusso dei dati, ma si scontrarono con la problematica che da sempre caratterizza l'analisi statica: il necessario compromesso da attuare tra performance ed accuratezza. L'efficacia delle tecniche di analisi statica è altamente condizionata dal fatto che devono essere gli sviluppatori ad utilizzarle, poichè prima si è in grado di identificare il difetto e minore sarà il costo della sua correzione.

\section{Applicazioni}
Sebbene le tecniche di analisi statica nacquero allo scopo di individuare difetti e di aderire a standard nella stesura del codice, molteplici successivi utilizzi vennero identificati ed implementati. \\
Attualmente l'analisi statica è utilizzata negli IDE\footnote{Integrated Development Environment} per evidenziare la sintassi e le parole chiave, restituendo al programmatore una migliore visualizzazione del sorgente del programma ed aiutandolo a rintracciare facilmente errori di battitura.\\
Sempre negli IDE viene utilizzata per segnalare eventuali errori nell'adesione alle regole definite da standard di scrittura del codice, come le spaziature, i rientri, la lunghezza delle righe ed il posizionamento delle parentesi. Sebbene questi standard possano risultare ai più superflui, quando il progetto in sviluppo viene realizzato da un numero elevato di sviluppatori è importante uniformare il codice al fine di ottenere una codebase leggibile.\\
I software di ottimizzazione del codice sfruttano l'analisi statica per determinare porzioni di codice che possono essere eseguite più velocemente se riorganizzate; tale analisi viene svolta valutando come le istruzioni riempirebbero la pipeline della CPU e riordinandole di conseguenza.\\
L'analisi statica è utilizzata anche a fini di generazione della documentazione; tali librerie leggono il contenuto delle annotations e dei commenti all'interno del codice sorgente per generare documenti che descrivono la struttura del programma. Tra questi si ricorda Doxygen\footnote{http://www.doxygen.org}, una delle librerie più utilizzate a questo scopo.\\
L'analisi statica è infine anche usata dai programmatori per capire il funzionamento, per calcolare le metriche e per rifattorizzare il codice sorgente.\\
In caso di software che possiede requisiti di sicurezza, ed ultimamente sempre più spesso visto il diffondersi di applicazioni critiche sotto questo punto di vista, l'analisi statica consente di individuare codice potenzialmente vulnerabile.

A seconda dell'utilizzo e dell'implementazione un'analisi statica varia totalmente per velocità di esecuzione, dalla rapidità di un'esecuzione per il controllo della sintassi alla lentezza di un'esecuzione alla ricerca di problematiche di sicurezza che considera il flusso dei dati. La complessità del task risulta essere solitamente direttamente proporzionale al tempo necessario per l'esecuzione e ciò influenza gli utilizzi di tale tipologia di analisi.

\section{Analisi statica vs. analisi dinamica vs. code review}
Le tecniche di analisi statica analizzano il sorgente di un programma in modo automatico senza eseguirlo. Prima della nascita di tali tecniche gli sviluppatori effettuavano un controllo manuale sul codice chiamato \emph{code review}.\\

La code review può essere eseguita da più sviluppatori (\emph{peer review}) oppure da un solo sviluppatore. E' una procedura complessa, che ha come requisito fondamentale la piena conoscenza delle decisioni architetturali prese durante la progettazione e la scrittura del codice oltre ad un'ottima padronanza del linguaggio in analisi. \\
Esistono due categorie di code review: \emph{formal code review} e \emph{lightweight code review}. La prima categoria richiede un dettagliato processo di analisi suddiviso in molteplici fasi. Tale metodologia comporta l'analisi di copie stampate del materiale ed è svolta da più partecipanti che contemporaneamente analizzano il codice.\\
La seconda categoria richiede meno formalismi rispetto alla precedente e viene svolta solitamente durante il normale processo di sviluppo. All'interno di essa si trovano le seguenti pratiche:
\begin{itemize}
\item Over-the-shoulder: uno sviluppatore osserva il codice che l'altro sta scrivendo per segnalare eventuali problemi
\item Email pass around: un SCM\footnote{Source Code Management System} invia tramite email il nuovo codice inserito nella codebase ad un soggetto che si occupa di effettuare la review.
\item Pair programming: Due sviluppatori scrivono codice contemporaneamente sulla stessa workstation. 
\item Tool-assisted code review: Sviluppatori e reviewers usano tools in grado di effettuare code review collaborativa.
\end{itemize}
La problematica di questa tipologia di analisi consiste nel tempo che richiede; i dati raccolti dai maggiori operatori del settore stimano che in media si possa effettuare code review su 150 linee di codice per ogni ora, fino a rimuovere l'85\% dei difetti presenti nel software.

L'analisi dinamica è una tecnica che consiste nell'osservare il comportamento del software durante la sua esecuzione. Al fine di rendere tale tecnica effettiva è necessario che il programma venga eseguito con diversi input. L'analisi dinamica è una tecnica precisa, che non comporta approssimazione poichè osserva l'esatto comportamento runtime dell'applicazione.
Lo svantaggio dell'analisi dinamica è la sua specificità: i risultati proposti riguardano solo ed esclusivamente quell'esecuzione, non c'è garanzia che la test suite utilizzata esegua effettivamente tutti i possibili data flow all'interno del software e che quindi esegua ogni porzione del codice in esame. L'approccio definito dall'analisi dinamica è particolarmente adatto per il testing ed il debugging.

Analisi statica ed analisi dinamica sono due approcci complementari che possono essere applicati allo stesso problema, i risultati hanno però diverse proprietà e l'esecuzione di ognuno ha diversi costi. Per tale ragione esistono soluzioni in grado di combinare analisi statica ed analisi dinamica al fine di ridurre i difetti tipici delle due tecniche e fornire risultati più attendibili.\\
Solitamente la combinazione di queste due tipologie consiste in tool di analisi dinamica che ispezionano dato in ingresso ed in uscita, usando la conoscenza ottenuta dall'analisi statica per aumentare l'accuratezza.\\
Un esempio di questa tipologie di tool è Saner, sviluppato da Balzarotti et. al.\cite{saner}, il quale utilizza un tool di analisi statica per effettuare il riconoscimento di routine custom  di sanitizzazione del codice, ed un'analisi dinamica successiva per valutarne l'efficacia. 