\chapter{Comparazione dei principali tool esistenti}
Nel seguente capitolo verranno esposte le modalità di funzionamento di alcuni tool che eseguono analisi statica di codice PHP al fine di trovare vulnerabilità. Verranno confrontati gli approcci e verrà valutata la possibile applicabilità durante il normale ciclo di sviluppo software. \\
Alcuni di questi tool sono effettivamente disponibili, altri sono dei prototipi accademici, altri ancora non supportano le versioni più recenti di PHP. l'obiettivo di tale sezione è quello di illustrare come la ricerca di vulnerabilità tramite analisi statica di codice PHP non presenti soluzioni affermate e si cercherà di spiegarne le motivazioni.

\section{Pixy}
Pixy è un tool di analisi statica scritto in Java per la detection di vulnerabilità in codice PHP 4, rilasciato sotto licenza GPL. Sviluppato da Jovanovic\ref{CITAZIONE} come lavoro accademico, inizialmente consentiva la ricerca di sole vulnerabilità di tipo XSS ma successivamente è stato esteso alla ricerca di altre vulnerabilità di tipo taint-style, come SQL injections e command injections.\\
Pixy è flow sensitive, ovvero prende in considerazione l'ordine delle istruzioni del programma e la scansione che effettua è di tipo globale (interprocedural analysis), ovvero non valuta una funzione singolarmente ma tiene in considerazione il contesto in cui viene eseguita. Inoltre Pixy è dotato di un meccanismo di analisi degli alias che consente di ridurre i numerosi falsi positivi che tale caratteristica del linguaggio potrebbe generare.\\
Pixy è disponibile anche in una versione web-based limitata sul sito ufficiale\footnote{http://pixybox.seclab.tuwien.ac.at/pixy/webinterface.php}.

La scansione di Pixy si basa sulla definizione di tre parametri:
\begin{itemize}
\item Gli entry points del programma: GET, POST e COOKIE.
\item Le funzioni di sanitizzazione: htmlentities, htmlspecialchars ed opportuno type casting.
\item Sensitive sinks: funzioni che ritornano output al browser, come print, echo, printf.
\end{itemize}
Queste definizioni sono stabilite tramite un file di configurazione in formato testuale.\\
L'obiettivo della scansione consiste nel determinare in quali circostanze è possibile che un dato tainted possa raggiungere un sensitive sink senza essere sanitizzato in modo opportuno. La tecnica per determinare ciò è quella della data-flow analysis, ovvero si computano in ogni punto del programma i possibili contenuti delle variabili per tracciare quali possono essere tainted. La data-flow analysis opera sul control flow graph del programma, quindi è necessario che prima dell'esecuzione venga costruito un albero (nello specifico un parse-tree) del file PHP in input. Tale operazione viene svolta con Jflex, un lexical analyzer scritto in java e Java Parser Cup, un generatore di parser in java.\\
Prima di eseguire la taint analysis sul control flow graph risultante vengono eseguite diverse operazioni, tra cui l'alias analysis (fornisce informazioni sugli alias) e la literal analysis (valuta le condizioni di branch ed esclude i percorsi che non possono essere eseguiti a run-time). Entrambe queste operazioni servono ad aumentare la precisione del tool, sebbene aumentino la complessità.\\
Pixy non considera le sanitizzazioni custom, generalmente effettuate con espressioni regolari, per due motivi: prima di tutto non è in grado di valutarle, inoltre si ritiene a priori che effettuare sanitizzazioni mediante l'uso di espressioni regolari sia una pessima decisione implementativa a causa della facilità di errore.

La grossa problematica che affligge Pixy è data dal fatto che non è in grado di parsare codice scritto per PHP 5. Le ingenti modifiche apportate da tale release al linguaggio hanno reso Pixy inadeguato per gli attuali progetti scritti in PHP.\\
Sebbene fosse molto promettente nel periodo in cui è stato sviluppato, il tool non riceve aggiornamenti dal 2007 e risulta effettivamente abbandonato. La mancanza di una solida community ha fatto si che nessuna terza parte abbia forkato il progetto per proseguirne lo sviluppo, rendendolo ormai troppo datato per l'utilizzo su codice sorgente attuale.

Secondo i risultati dei test eseguiti dall'autore[12 su paper depoel] Pixy ha una percentuale di falsi positivi che si aggira intorno al 50\%, soglia considerata dall'autore stesso accettabile per un tool di analisi statica su un linguaggio fortemente dinamico come PHP. Secondo le analisi eseguite da de Poel[CITAZONE] nel 2010, durante la scansione del codice sorgente di alcuni progetti open source viene dimostrato che Pixy non è in grado di funzionare con codebase recenti, la scansione ha riportato risultati per solo cinque su sedici dei software analizzati e, neppure in questi casi, i risultati sono stati attendibili.

\section{Saner}
Saner è un prototipo, basato su Pixy, che combina le peculiarità di un'analisi statica con quelle di un'analisi dinamica.
Sviluppato da Balzarotti et.al.\cite{CITAZIONE} dimostra come sia possibile combinare due approcci a prima vista molto differenti per migliorare i risultati ottenuti.\\
La parte di analisi statica viene eseguita da Pixy, che si occupa di determinare in che modo l'applicazione processa l'input, individuando eventuali sanitizzazioni incomplete. Successivamente interviene una fase di analisi dinamica che si occupa di ricostruire il codice responsabile per la sanitizzazione dell'input. Una volta ricostruito, Saner processa tale codice con input malevoli per individuare eventuali problemi nelle sanitizzazioni.\\
Facendo affidamento sull'analisi dinamica, Saner è in grado di valutare eventuali sanitizzazioni custom al posto di reputarle direttamente come inaffidabili, cosa che il solo Pixy era costretto a fare.\\
Nell'esempio seguente viene evidenziato il valore del contributo dell'analisi dinamica nella scelta della giusta decisione da intraprendere.

[ESEMPIO DA PAPER SANER]

La maggior parte dei tool di analisi statica avrebbero marchiato la prima parte del codice riportato come safe a causa della presenza del costrutto htmlentities, che solitamente fa parte delle funzioni di sanitizzazione. Nel secondo caso però è presente una sanitizzazione custom costruita con la funzione str\_replace. Siccome str\_replace non fa parte delle funzioni di sanitizzazione, il codice viene marchiato come unsafe ed un warning viene riportato all'utente. Saner consente di eseguire tale sanitizzazione in modo dinamico sfruttando input appositamente malevoli al fine di verificare l'efficacia della sanitizzazione stessa, riducendo il numero di warning.\\
In un certo senso, Saner automatizza le operazioni che uno sviluppatore dovrebbe fare per verificare se un warning riportato da un tool di analisi statica è effettivamente una problematica di sicurezza.

I risultati riportati dall'autore dimostrano come la fase di analisi dinamica aumenti in modo elevato l'affidabilità del tool. Nell'analisi di cinque applicativi open-source di media complessità, Pixy segnala l'incapacità di determinare il valore della procedura di sanitizzazione per ben 66 sinks. Con l'ausilio dell'analisi dinamica è stato possibile determinare l'effettiva presenza di 14 vulnerabilità, per i restanti 52 sinks l'analisi non è stata in grado di determinare dei valori di input che bypassassero la sanitizzazione.

\section{RIPS}
RIPS è un tool per l'analisi statica di codice PHP rivolto alla ricerca di vulnerabilità sviluppato da Johannes Dahse.
E' l'unico tool open source scritto in PHP considerato usabile attualmente in sviluppo.\\
Il tool è in grado di individuare vulnerabilità di tipo XSS, SQL Injection, file disclosure, code evaluation, remote command execution e busines logic flaw attraverso dei rule-sets definiti nei propri file di configurazione.\\
RIPS lavora in due fasi, costruzione del modello e analisi. Nella fase di costruzione del modello si possono individuare le operazioni di analisi semantica e lessicale, parsing e control flow analysis. Nella fase di analisi si individuano le operazione di taint analysis e local and global analysis.

La fase di analisi lessicale e semantica è caratterizzata dall'uso della libreria built-in \emph{tokenizer} per trasformare i costrutti del linguaggio in uno stream di tokens, attraverso l'uso della funzione \emph{token\_get\_all()} che trasforma ogni istruzione del linguaggio in un array costituito dal token, dal numero di riga dell'istruzione e dal codice originale. Successivamente vengono rimossi i tokens ritenuti inutili per l'analisi, come le spaziature ed il codice HTML, e trasformati alcuni tokens in equivalenti strutture più semplici da parsare (ad esempio vengono convertiti i costrutti di branches realizzati mediante la forma compatta in classici costrutti if-else).\\
La fase successiva, quella di parsing, avviene attraverso l'analisi dello stream di tokens una sola volta per ogni file, al fine di garantire le migliori performance. In questa fase viene creata per ogni file una lista delle dipendenze e per alcuni costrutti vengono eseguite operazioni particolari. In caso di \emph{T\_INCLUDE} ad esempio lo stream di tokens del file da includere viene aggiunto allo stream corrente, in caso di \emph{T\_VARIABLE} viene controllato lo scope della variabile, ovvero se è una variabile globale o locale, e di conseguenza viene aggiunta ad una lista.\\
La fase di control flow analysis avviene in modo estremamente diverso da Pixy: se nel tool di Jovanovic si faceva riferimento al control flow graph, in RIPS la generazione dello stesso è stata evitata per problemi di performance. RIPS esegue la control flow analysis sfruttando la presenza di alcuni tokens come le parentesi graffe, \emph{T\_EXIT} e \emph{T\_THROW} che danno indicazioni sulle uscite da flussi di istruzioni.

La fase di analisi si basa sulle direttive definite attraverso array PHP nei file di configurazione. Tali direttive indicano gli input, i sinks, le funzioni di sanitizzazione con i rispettivi parametri da tracciare ed i token da ignorare.\\
RIPS cerca chiamate a funzioni, controlla se la funzione trovata è nella lista dei sinks ed in caso affermativo valuta i parametri di tale funzione. Una volta individuati i parametri rilevanti controlla nelle liste precedentemente create di variabili globali e locali se tali possono essere o meno tainted. In caso affermativo viene riportata la potenziale vulnerabilità.\\
RIPS è in grado di determinare se una funzione definita dall'utente è o meno un sink. Nel caso in cui ciò accada infatti l'algoritmo può risalire ai parametri di input e quindi comprendere se il sink è determinato da uno di essi. In caso affermativo oltre alla funzione stessa anche le chiamate ad essa vengono trattate come un sink.

RIPS possiede una configurabile interfaccia web che consente di lanciare la scansione e che riporta i risultati. Tale interfaccia consente di definire per quali vulnerabilità effettuare la scansione, il livello di verbosity della scansione e se comprendere le sottodirectory o meno. Il report dei risultati è dettagliato, vengono mostrate le linee di codice sorgente che riportano problematiche,  

\chapter{Vulture}
Vulture è un concept/prototipo di tool per analisi statica volta alla ricerca di vulnerabilità di applicazioni web, creato dal sottoscritto in collaborazione con EURECOM.\\
Il progetto nasce con l'idea di costruire una piattaforma estensibile, alla quale lo sviluppatore può aggiungere i propri insiemi di regole volte alla ricerca di vulnerabilità. 

Vulture non è attualmente completo ed usabile, è stata implementata solo una parte delle caratteristiche progettate. 


\section{Problematiche}

\section{Sviluppi futuri}

\chapter{Discussione}

\chapter{Conclusioni}